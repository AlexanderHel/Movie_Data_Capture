# For detailed tutorials, please see
# - https://github.com/yoshiko2/Movie_Data_Capture/wiki#%E9%85%8D%E7%BD%AEconfigini
[common]
main_mode = 1
source_folder = ./
failed_output_folder = failed
success_output_folder = JAV_output
link_mode = 0
; 0: Do not scrape hard-linked files 1: Scrape hard-linked files
scan_hardlink = 0
failed_move = 0
auto_exit = 0
translate_to_sc = 0
multi_threading = 0
;actor_gender value: female(♀) or male(♂) or both(♀ ♂) or all(♂ ♀ ⚧)
actor_gender = female
del_empty_folder = 1
;NFOs that have been newly modified in the last (default:30) days can be avoided when finishing mode (main_mode=3) and soft link (soft_link=0)
;repeatedly scrape the top video files, 0 for processing all video files
nfo_skip_days = 1
ignore_failed_list = 0
download_only_missing_images = 1
mapping_table_validity = 7
; Some jellyfin-specific settings (0: not on, 1: on) such as
; tags and genres are duplicated in jellyfin, so you can just save genres to nfo
; In jellyfin you only need to save thumb, not fanart
jellyfin = 1
; After opening tag and genere only show actors
; show only actors after opening tag and genere
actor_only_tag = 0
sleep = 3

[advenced_sleep]
; Stop after processing how many video files, 0 for processing all video files
stop_counter = 0
; Re-run delay time, unit: h hours m minutes s seconds Example: 1h30m45s (1 hour 30 minutes 45 seconds) 45 (45 seconds)
; Only if the stop_counter is not zero, the rerun_delay is delayed for seconds after each stop_counter movie is processed
rerun_delay = 9m60s
; The above parameters can be used in conjunction to scrape or sort thousands of files in small increments without triggering translation or metadata blocking

[proxy]
;proxytype: http or socks5 or socks5h switch: 0 1
switch = 0
type = http
proxy = 
timeout = 20
retry = 3
cacert_file =

[Name_Rule]
location_rule = actor+'/'+number
naming_rule = number+'-'+title
max_title_len = 50
; Whether to name the picture as a number after scraping
image_naming_with_number = 0

[update]
update_check = 1

[priority]
website = javdb,avsox,fc2,carib,gcolle,javbus,javmenu
;jairav,jav321,fanza,xcity,mgstage,dlsite,madou,mv91,javday,getchu
[escape]
literals = \()/
folders = failed,JAV_output

[debug_mode]
switch = 1

; Machine Translation
[translate]
switch = 1
;optional google-free,azure,deeplx
engine = deeplx
;azure translation key
key =
; translation delay
delay = 1
values = title,outline
; google translation service site, or deeplx access link
service_site = translate.google.com

; Trailer
[trailer]
switch = 0

; Used to determine if it is uncensored
[uncensored]
uncensored_prefix = PT-,S2M,BT,LAF,SMD,SMBD,SM3D2DBD,SKY-,SKYHD,CWP,CWDV,CWBD,CW3D2DBD,MKD,MKBD,MXBD,MK3D2DBD,MCB3DBD,MCBD,RHJ,MMDV

[media]
; Media Suffix
media_type = .mp4,.avi,.rmvb,.wmv,.mov,.mkv,.flv,.ts,.webm,.iso,.mpg,.m4v
; Subtitle suffix
sub_type = .smi,.srt,.idx,.sub,.sup,.psb,.ssa,.ass,.usf,.xss,.ssf,.rt,.lrc,.sbv,.vtt,.ttml

; Watermark
[watermark]
switch = 1
water = 2
; top left 0, top right 1, bottom right 2, bottom left 3

; fanart
[extrafanart]
switch = 1
parallel_download = 5
extrafanart_folder = extrafanart

; Plot Summary
[storyline]
switch = 1
;If website is javbus javdb avsox xcity carib, site censored_site uncensored_site is the site to get the plot synopsis information.
; Optional list of data source sites. The list of sites concurrently queried, the priority of the values taken by the serial number before the colon, from small to large, the number of small sites no data will be used only after the site obtained.
;The difference is that airav can only check the code, avno1 airavwiki can check the code and no code.
;The difference is that airav can only check for code, avno1 airavwiki can check for both code and no code, 58avgo can only check for no code or outflow crack mosaic movies (this feature is not used).
;xcity and amazon are Japanese, because amazon mall does not have number information, the accuracy of the corresponding DVD selected is only 99.6%. If all three lists are empty, then no query.
; set to not query can significantly improve the speed of scraping.
; site=
site = airavwiki
censored_site = airavwiki,xcity
uncensored_site = airavwiki,58avgo
;run_mode: 0: sequential execution (slowest) 1: thread pool (default) 2: process pool (start-up overhead is larger than thread pool, the more concurrent sites the faster)
run_mode = 1
;show_result plot debug information 0 off 1 abbreviated 2 detailed (the detailed part is not recorded in the log), the plot profile fails when you can open 2 to see the reason
show_result = 1

;Convert from traditional to simple mode mode=0:no conversion 1:english ( only support vars = tag )
[cc_convert]
mode = 1
vars = tag

[javdb]
sites = 38,39,40

; face recognition locations_model=hog:directional gradient histogram(not very accurate, fast) cnn:deep learning model(accurate, need GPU/CUDA, slow)
; uncensored_only=0:face recognition for all covers 1:identify only the uncensored cover, with code cover directly cut the right half
;aways_imagecut=0: default behavior by each website 1: always crop covers, turn this on to ignore [common]download_only_missing_images=1 always overwrite covers
;The aspect ratio of the cover crop is configurable, the formula is aspect_ratio/3. default aspect_ratio=2.12: match most coded movie covers, the previous version default is 2/3 i.e. aspect_ratio=2
[face]
locations_model = hog
uncensored_only = 1
aways_imagecut = 0
aspect_ratio = 2.12

[jellyfin]
multi_part_fanart = 1

[actor_photo]
download_for_kodi = 0
